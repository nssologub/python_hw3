
123
\section{Компьютерная модель и численные результаты}
\subsection{Описание}
Компьютерная модель реализована на языке Python и описывает поведение однородной  векторной цепи Маркова с частичными связями. Все параметры, указанные в п. ``Параметры модели'', могут быть заданы.

В модели реализованы следующие функции:
\begin{itemize}
\item при известных параметрах $HVMC(s, M_r)$ генерировать случайно последовательность произвольной длины;
\item строить двумерную матрицу одношаговых переходов $P$ при известной $(r+1)$-мерной матрице $Q$;
\item вычислять стационарное распределение теоретически (как решение системы) и экспериментально на основе релизации;
\item по имеющейся реализации строить оценки неизвестных параметров.

\end{itemize}


 Текст программы приведен в Приложении А.

\subsection{Параметры модели}
\begin{enumerate}
\item[] $N$ – число состояний;
\item[] $V$ -- пространство состояний;
\item[] $m$ – число компонент вектора;
\item[] $s$ – порядок цепи Маркова;
\item[] $p^{(1)}$ – начальное распределение вероятностей;
\item[] $M_r, r$ – шаблон-множество частичных связей и число связей соответственно;
\item[] $T$ – число наблюдений;
\item[] $q_{(\alpha_{1}, \dots, \alpha_{r}), J_{s+1}}$ -- матрица вероятностей одношаговых переходов.
\end{enumerate}




\subsection{Статистическая оценка матрицы одношаговых переходов}
Вычислим состоятельные оценки условных вероятностей по наблюдаемой реализации\\
 
$x_1, x_2, \ldots, x_T \in V^m$, $x_t = \left(x_{1,t}, x_{2,t} \right)^T$, $x_{i,t} \in \{0, 1\}:$
\begin{equation}
\begin{split}
\mathbf{\hat  P} \{x_{n}=I | \alpha_{1}=i_1 , \alpha_2=i_2\}=\frac{ m (x_{n}=I , \alpha_{1}=i_1 , \alpha_2=i_2)}{ m ( \alpha_{1}=i_3 , \alpha_2=i_4)},
\end{split}
 \end{equation}
где $m(A)$ - количество наступлений события $A$ за все время наблюдения $T$.

Построим таблицу  при количестве наблюдений $T=10^6$:\\
\begin{table}[h]
\caption{Оценка матрицы  $\mathbf{P}$ и ее ошибка}
\label{table:p_est}
\begin{center}
\begin{tabular}{|c|c|c|}
\hline
$\mathbf{\hat  P_i}$ & $\mathbf{  P_i}$ &$\varepsilon_{i}$\\ \hline

0,10083&0,1&0,00083\\ \hline
0,29925&0,3&0,00075\\ \hline
0,2014&0,2&0,0014\\ \hline
0,39852&0,4&0,00148\\ \hline
0,10016&0,1&0,00016\\ \hline
0,09984&0,1&0,00016\\ \hline
0,1011&0,1&0,0011\\ \hline
0,6989&0,7&0,0011\\ \hline
0,24957&0,25&0,00043\\ \hline
0,25025&0,25&0,00025\\ \hline
0,24971&0,25&0,00029\\ \hline
0,25047&0,25&0,00047\\ \hline
0,09969&0,1&0,00031\\ \hline
0,40148&0,4&0,00148\\ \hline
0,39889&0,4&0,00111\\ \hline
0,09994&0,1&0,00006\\ \hline
\end{tabular}
\end{center}
\end{table}

В таблице  \ref{table:p_est} величина $\varepsilon_{i} =|\mathbf{\hat  P_i}-\mathbf{  P_i}|$ -- ошибка оценки, $i \in \{0, N^{ms}-1\}$. 
Видно, что построенная компьютерная модель соответствует теоретической модели векторной цепи Маркова с частичными связями.

На рисунке \ref{img:eps_ov_T}  представлен график зависимости средней ошибки от количества наблюдений в реализации. Для этого для каждого $T_{fix}$ проведем 100 реализаций. Значение ошибки $j$-той реализации длительности $T$ определяем как $ \varepsilon_T^{(j)}=\max_{i}{ \varepsilon_{iT}^{(j)}}$. Тогда значение  $\varepsilon_T = \frac{1}{100}\sum\limits_{j=1}^{100} \varepsilon_T^{(j)}$.

\newpage
\begin{figure}[h]
\begin{center}
\caption{Зависимость ошибки $\varepsilon_T$ от длины реализации $T$}
\label{img:eps_ov_T}
\setkeys{Gin}{width=0.7\textwidth}
\includegraphics{sologub/eFromT.pdf}
\end{center}	
\end{figure}






\subsection{Статистическая оценка шаблона связей}
Воспользуемся реализацией, сгенерированной в предыдущих пунктах, с заданными параметрами  для оценки шаблона связей $M_r$. Переберем все возможные шаблоны $M_r$ и для каждого из них оценим матрицу одношаговых переходов $\hat Q = ( \hat q_{\A, J})$, а затем энтропию $\hat H(M_r)$ по формуле $(\ref{entropy})$:
\begin{equation}
\hat H(M_r) = -\sum_{\A, J}m(\A, J) \ln{\hat q_{\A, J}}.
\end{equation}

\begin{table}[h]
\caption{Оценка энтропии $\hat H(M_r)$ в зависимости от шаблона $M_r$}
\label{table:entropy_est}
\begin{center}
\begin{tabular}{|c|c|}
\hline
$M_r$ & $\hat H(M_r)$ \\ \hline
((0, 0), (1, 0)) & 124660.676917 \\ \hline
((0, 0), (0, 1)) & 124625.655747 \\ \hline
((0, 0), (1, 1)) & 119634.530799 \\ \hline
((1, 0), (0, 1)) & 134189.536698 \\ \hline
((1, 0), (1, 1)) & 133297.542562 \\ \hline

\end{tabular}
\end{center}
\end{table}

Выбирая шаблон, на котором достигается минимум $\hat H(M_r)$, получаем оценку шаблона 
$$\hat M_r = \begin{pmatrix}1 & 0 \\ 0 & 1\end{pmatrix}.$$
Полученная оценка совпадает с начальным шаблоном связей.

\subsection{Совместное оценивание неизвестных параметров}
Пусть имеется реализация  $HVMC(s, M_r)$ и необходимо оценить все параметры модели.
Возьмем ранее полученную реализацию при $T = 10^5$. 

Будем перебирать все пары $(s,r)$ и все шаблоны $M_r$, однако шаблон выбираем так, чтобы хотя бы одна связь находилась на расстоянии $(s + 1)$ от текущего вектора (иначе значение $s$ было бы меньше).

Построим таблицу значений функции $AIC(s,r)$ при оптимальном шаблоне (см. Таблицу \ref{table:entropy_est}).
 \begin{table}[h]
\caption{Зависимость $AIC(s,r)$ от шаблона $M_r$}
\label{table:joint_est}
\begin{center}
\begin{tabular}{|c|c|c|c|}
\hline
$s$ & $r$ & $M_r$ & $AIC(s, r)$ \\ \hline
1 & 1 & ((1, 0)) & 266868.504003 \\ \hline
1 & 2 & ((0, 0), (1, 0)) & 266875.400643 \\ \hline
2 & 1 & ((0, 0)) & 249485.259598 \\ \hline
2 & 2 & ((0, 0), (1, 1)) & 239138.934384 \\ \hline
2 & 3 & ((0, 0), (0, 1), (1, 1)) & 239152.535635 \\ \hline
3 & 1 & ((0, 0)) & 268550.314843 \\ \hline
3 & 2 & ((0, 0), (0, 1)) & 249022.804225 \\ \hline
3 & 3 & ((1, 0), (0, 1), (1, 2)) & 239145.5327 \\ \hline
4 & 1 & ((0, 0)) & 267107.809214 \\ \hline
4 & 2 & ((0, 0), (0, 2)) & 249474.577506 \\ \hline
4 & 3 & ((0, 0), (0, 2), (1, 3)) & 239145.169153 \\ \hline
5 & 1 & ((1, 0)) & 268588.144084 \\ \hline
5 & 2 & ((0, 0), (0, 3)) & 249457.267107 \\ \hline
5 & 3 & ((0, 0), (0, 3), (1, 4)) & 239145.634599 \\ \hline

\end{tabular}
\end{center}
\end{table}

Минимум $AIC(s,r)$ достигается при $s = 2$, $r = 2$, $M_r = ((0,0),(1,1))$. Мало отличаются также значения $AIC$ при следующих шаблонах:
\begin{enumerate}
\item $\begin{pmatrix}1 & 0 \\ 1 & 1\end{pmatrix}$ $s = 2, r = 3$;
\item $\begin{pmatrix}0 & 1 & 0 \\ 1 & 0 & 1\end{pmatrix}$ $s=3, r=3$;
\item
  $\begin{pmatrix}1&0&1&0\\0&0&0&1\end{pmatrix}$ $s=4, r=3$;
\item
$\begin{pmatrix}1& 0&0&1&0\\0&0&0&0&1\end{pmatrix}$ $s=5, r=3$.

\end{enumerate} 
Это объясняется тем фактом, что  все они содержат в себе истинный шаблон $M_r=\begin{pmatrix}1 & 0 \\ 0 & 1\end{pmatrix}$.
